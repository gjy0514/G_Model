import torch
import torchvision
import torch.nn as nn
from torch import optim
import torch.nn.functional as F
import torchvision.transforms as transforms
from torch.utils.data import DataLoader,Dataset
import matplotlib.pyplot as plt
import torchvision.utils
import numpy as np
import random
from PIL import Image
import PIL.ImageOps

train_batch_size = 32       
train_number_epochs = 200    

def imshow(img,text=None,should_save=False):
    #展示一幅tensor图像，输入是(C,H,W)
    npimg = img.numpy() #将tensor转为ndarray
    plt.axis("off")
    if text:
        plt.text(75, 8, text, style='italic',fontweight='bold',
            bbox={'facecolor':'white', 'alpha':0.8, 'pad':10})
    plt.imshow(np.transpose(npimg, (1, 2, 0))) #转换为(H,W,C)
    plt.show()

def show_plot(iteration,loss):
    plt.plot(iteration,loss)
    plt.show()


# 自定义Dataset类，__getitem__(self,index)每次返回(img1, img2, 0/1)
class SiameseNetworkDataset(Dataset):

    def __init__(self, imageFolderDataset, transform=None, should_invert=True):
        self.imageFolderDataset = imageFolderDataset
        self.transform = transform
        self.should_invert = should_invert

    def __getitem__(self, index):
        img0_tuple = random.choice(self.imageFolderDataset.imgs)  
        should_get_same_class = random.randint(0, 1)  
        if should_get_same_class:
            while True:
                img1_tuple = random.choice(self.imageFolderDataset.imgs)
                if img0_tuple[1] == img1_tuple[1]:
                    break
        else:
            while True:
                img1_tuple = random.choice(self.imageFolderDataset.imgs)
                if img0_tuple[1] != img1_tuple[1]:
                    break

        img0 = Image.open(img0_tuple[0])
        img1 = Image.open(img1_tuple[0])
        img0 = img0.convert("L")
        img1 = img1.convert("L")

        if self.should_invert:
            img0 = PIL.ImageOps.invert(img0)
            img1 = PIL.ImageOps.invert(img1)

        if self.transform is not None:
            img0 = self.transform(img0)
            img1 = self.transform(img1)

        return img0, img1, torch.from_numpy(np.array([int(img1_tuple[1] != img0_tuple[1])], dtype=np.float32))

    def __len__(self):
        return len(self.imageFolderDataset.imgs)



training_dir = "训练集地址" 
folder_dataset = torchvision.datasets.ImageFolder(root=training_dir)


transform = transforms.Compose([transforms.Resize((100, 100)),  
                                transforms.ToTensor()])
siamese_dataset = SiameseNetworkDataset(imageFolderDataset=folder_dataset,
                                        transform=transform,
                                        should_invert=False)

train_dataloader = DataLoader(siamese_dataset,
                              shuffle=True,
                              batch_size=train_batch_size)


class SiameseNetwork(nn.Module):
    def __init__(self):
        super().__init__()
        self.cnn1 = nn.Sequential(
            nn.ReflectionPad2d(1),
            nn.Conv2d(1, 4, kernel_size=3),
            nn.ReLU(inplace=True),
            nn.BatchNorm2d(4),

            nn.ReflectionPad2d(1),
            nn.Conv2d(4, 8, kernel_size=3),
            nn.ReLU(inplace=True),
            nn.BatchNorm2d(8),

            nn.ReflectionPad2d(1),
            nn.Conv2d(8, 8, kernel_size=3),
            nn.ReLU(inplace=True),
            nn.BatchNorm2d(8),
        )

        self.fc1 = nn.Sequential(
            nn.Linear(8 * 100 * 100, 500),
            nn.ReLU(inplace=True),

            nn.Linear(500, 500),
            nn.ReLU(inplace=True),

            nn.Linear(500, 5))

    def forward_once(self, x):
        output = self.cnn1(x)
        output = output.view(output.size()[0], -1)
        output = self.fc1(output)
        return output

    def forward(self, input1, input2):
        output1 = self.forward_once(input1)
        output2 = self.forward_once(input2)
        return output1, output2


class ContrastiveLoss(torch.nn.Module):
    def __init__(self, margin=2.0):
        super(ContrastiveLoss, self).__init__()
        self.margin = margin

    def forward(self, output1, output2, label):
        euclidean_distance = F.pairwise_distance(output1, output2, keepdim=True)
        loss_contrastive = torch.mean((1 - label) * torch.pow(euclidean_distance, 2) +
                                      (label) * torch.pow(torch.clamp(self.margin -
                                                                      euclidean_distance, min=0.0), 2))

        return loss_contrastive


#net = SiameseNetwork().cuda()  
net = SiameseNetwork()  
criterion = ContrastiveLoss()  
optimizer = optim.Adam(net.parameters(), lr=0.0005)  

counter = []
loss_history = []
iteration_number = 0

if __name__ == '__main__':
    train = 1
    test = 0
    if train:
        print("——————training——————")
        for epoch in range(0, train_number_epochs):
            for i, data in enumerate(train_dataloader, 0):
                img0, img1, label = data
                # img0维度为torch.Size([32, 1, 100, 100])，32是batch，label为torch.Size([32, 1])
                #img0, img1, label = img0.cuda(), img1.cuda(), label.cuda()  # 数据移至GPU
                optimizer.zero_grad()
                output1, output2 = net(img0, img1)
                loss_contrastive = criterion(output1, output2, label)
                loss_contrastive.backward()
                optimizer.step()

                if i % 10 == 0:
                    iteration_number += 10
                    counter.append(iteration_number)
                    loss_history.append(loss_contrastive.item())
            print("Epoch number: {} , Current loss: {:.4f}".format(epoch, loss_contrastive.item()))

        torch.save(net.state_dict(), 'net_parameters.pkl')
        print("——————parameter saved——————")
        show_plot(counter, loss_history)

    if test:
        print("——————testing——————")
        net.load_state_dict(torch.load('net_parameters.pkl'))
        print("——————parameter loaded——————")
        testing_dir = "测试集地址" 
        folder_dataset_test = torchvision.datasets.ImageFolder(root=testing_dir)

        transform_test = transforms.Compose([transforms.Resize((100, 100)),
                                             transforms.ToTensor()])
        siamese_dataset_test = SiameseNetworkDataset(imageFolderDataset=folder_dataset_test,
                                                     transform=transform_test,
                                                     should_invert=False)

        test_dataloader = DataLoader(siamese_dataset_test,
                                     shuffle=True,
                                     batch_size=1)

        dataiter = iter(test_dataloader)
        x0, _, _ = next(dataiter)
        for i in range(10):
            _, x1, label2 = next(dataiter)
            concatenated = torch.cat((x0, x1), 0)
            #output1, output2 = net(x0.cuda(), x1.cuda())
            output1, output2 = net(x0, x1)
            euclidean_distance = F.pairwise_distance(output1, output2)
            imshow(torchvision.utils.make_grid(concatenated), 'Dissimilarity: {:.2f}'.
                   format(euclidean_distance.item()))



